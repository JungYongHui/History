{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 필요한 함수 정의\n",
    "def make_datetime(x):\n",
    "    # string 타입의 Time column을 datetime 타입으로 변경\n",
    "    x     = str(x)\n",
    "    year  = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day   = int(x[6:8])\n",
    "    hour  = int(x[8:10])\n",
    "    #mim  = int(x[10:12])\n",
    "    #sec  = int(x[12:])\n",
    "    return dt.datetime(year, month, day, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    param_grid = [{'loss':['exponential'],\n",
    "                  'learning_rate':[0.01,0.1,0.2],\n",
    "                  'max_depth':[8, 12],\n",
    "                  'max_features':['log2'],\n",
    "                  'criterion':['friedman_mse'],\n",
    "                  'n_estimators':[30, 40]}]\n",
    "    \n",
    "    model = GradientBoostingClassifier()\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,\n",
    "                     param_grid=param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     n_jobs=-1)\n",
    "\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    y_prob = np.round(gs.predict_proba(X_test), 2)\n",
    "    y_prob = y_prob[:, 1]\n",
    "    y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print('gradient boosting')\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    return acc, precision, recall, auc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    param_grid = [{'loss':['log', 'modified_huber'],\n",
    "                  'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "                  #'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1]\n",
    "                  }]\n",
    "    \n",
    "    model = SGDClassifier()\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,\n",
    "                     param_grid=param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     n_jobs=-1)\n",
    "\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    y_prob = np.round(gs.predict_proba(X_test), 2)\n",
    "    y_prob = y_prob[:, 1]\n",
    "    y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print('SGD')\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    return acc, precision, recall, auc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= 1 =================================\n",
      "gradient boosting\n",
      "0.8125282927485984\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 40}\n",
      "SGD\n",
      "0.697383834863951\n",
      "{'alpha': 0.0001, 'loss': 'log', 'penalty': 'l1'}\n",
      "GB accuracy:  0.7878\n",
      "GB auc:  0.8088238109065482\n",
      "SGD accuracy:  0.6618\n",
      "SGD auc:  0.6144092527101681\n",
      "========================= 2 =================================\n",
      "gradient boosting\n",
      "0.8115920234785365\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 40}\n",
      "SGD\n",
      "0.6845025759430101\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "GB accuracy:  0.7896\n",
      "GB auc:  0.8124587065083542\n",
      "SGD accuracy:  0.697\n",
      "SGD auc:  0.6267854465149884\n",
      "========================= 3 =================================\n",
      "gradient boosting\n",
      "0.8067572743765432\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 40}\n",
      "SGD\n",
      "0.6903865608728992\n",
      "{'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'}\n",
      "GB accuracy:  0.7932\n",
      "GB auc:  0.8190103548536276\n",
      "SGD accuracy:  0.6656\n",
      "SGD auc:  0.5157474175984683\n",
      "----------------------- final result ------------------------------\n",
      "GB average of accuracy 0.7902\n",
      "GB average of AUC 0.8134309574228432\n",
      "SGD average of accuracy 0.6748\n",
      "SGD average of AUC 0.5856473722745417\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    pd.options.display.max_columns=None\n",
    "    \n",
    "    dataframe = pd.read_csv('train_set.csv')\n",
    "    dataframe.index = np.arange(10000, 25000)\n",
    "    \n",
    "    train_prob = pd.read_csv('train_problem_data.csv')\n",
    "    problem = np.zeros(15000)\n",
    "    problem[train_prob.user_id.unique()-10000] = 1 \n",
    "    \n",
    "    X = dataframe.astype(float).values\n",
    "    y = problem\n",
    "    \n",
    "    kf = KFold(n_splits=3)\n",
    "    i=1\n",
    "    \n",
    "    acc_list, precision_list, recall_list, auc_list = [], [], [], []\n",
    "    acc_list2, precision_list2, recall_list2, auc_list2 = [], [], [], []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print('=========================', i, '=================================')\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        acc1, precision1, recall1, auc1, model = GB(X_train, X_test, y_train, y_test)\n",
    "        acc2, precision2, recall2, auc2, model2 = SGD(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # GB\n",
    "        print('GB accuracy: ', acc1)\n",
    "        print('GB auc: ', auc1)\n",
    "        \n",
    "        acc_list.append(acc1)\n",
    "        precision_list.append(precision1)\n",
    "        recall_list.append(recall1)\n",
    "        auc_list.append(auc1)\n",
    "        \n",
    "        # SGD\n",
    "        print('SGD accuracy: ', acc2)\n",
    "        print('SGD auc: ', auc2)\n",
    "        \n",
    "        acc_list2.append(acc2)\n",
    "        precision_list2.append(precision2)\n",
    "        recall_list2.append(recall2)\n",
    "        auc_list2.append(auc2)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    print('----------------------- final result ------------------------------')\n",
    "    print('GB average of accuracy', np.mean(acc_list))\n",
    "    print('GB average of AUC', np.mean(auc_list))\n",
    "    print('SGD average of accuracy', np.mean(acc_list2))\n",
    "    print('SGD average of AUC', np.mean(auc_list2))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
